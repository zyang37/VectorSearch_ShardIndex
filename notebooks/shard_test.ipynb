{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import faiss\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "# from faiss import write_index, read_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_floats(size, low=0, high=1):\n",
    "    return [np.random.uniform(low, high) for _ in range(size)]\n",
    "\n",
    "def random_normal_vectors(num_embeds, dim, mean=0, std=1):\n",
    "    data = np.random.normal(mean, std, (num_embeds, dim)).astype('float32')\n",
    "    return data\n",
    "\n",
    "def random_embeddings(num_embeds, dim):\n",
    "    # create random embeddings\n",
    "    data = np.random.random((num_embeds, dim)).astype('float32')\n",
    "    # data[:, 0] += np.arange(num_embeds) / 1000.\n",
    "    return data\n",
    "\n",
    "def random_queries(num_queries, dim):\n",
    "    # create random queries\n",
    "    queries = np.random.random((num_queries, dim)).astype('float32')\n",
    "    # queries[:, 0] += np.arange(num_queries) / 1000.\n",
    "    return queries\n",
    "\n",
    "def save_np_to_file(file_path, np_array):\n",
    "    np.save(file_path, np_array)\n",
    "    print(f\"Saved to {file_path}\")\n",
    "\n",
    "# load npy file\n",
    "def load_npy(npy_path):\n",
    "    return np.load(npy_path)\n",
    "\n",
    "def create_ivf_index(npy_path):\n",
    "    # load npy file\n",
    "    data = load_npy(npy_path)\n",
    "    nlist = 100\n",
    "    # print(data.shape)\n",
    "    d = data.shape[1]\n",
    "    quantizer = faiss.IndexFlatL2(d)  # the other index\n",
    "    index = faiss.IndexIVFFlat(quantizer, d, nlist, faiss.METRIC_L2)\n",
    "    assert not index.is_trained\n",
    "    index.train(data)\n",
    "    assert index.is_trained\n",
    "    # save index and embeds\n",
    "    index.add(data)\n",
    "    return index\n",
    "\n",
    "def create_flat_index(npy_path):\n",
    "    # KNN search\n",
    "    data = load_npy(npy_path)\n",
    "    dim = data.shape[1]\n",
    "    index = faiss.IndexFlatL2(dim)\n",
    "    index.add(data)\n",
    "    return index\n",
    "\n",
    "def save_index(index, index_path):\n",
    "    faiss.write_index(index, index_path)\n",
    "\n",
    "def compute_embeds_avgs(embeds):\n",
    "    return np.mean(embeds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to ../shards/npys/embeds_0.npy\n",
      "Saved to ../shards/npys/embeds_1.npy\n",
      "Saved to ../shards/npys/embeds_2.npy\n",
      "Saved to ../shards/npys/embeds_3.npy\n",
      "Saved to ../shards/npys/embeds_4.npy\n",
      "Saved to ../shards/npys/embeds_5.npy\n",
      "Saved to ../shards/npys/embeds_6.npy\n",
      "Saved to ../shards/npys/embeds_7.npy\n",
      "Saved to ../shards/npys/embeds_8.npy\n",
      "Saved to ../shards/npys/embeds_9.npy\n",
      "Saved to ../shards/npys/embeds_10.npy\n",
      "Saved to ../shards/npys/embeds_11.npy\n",
      "Saved to ../shards/npys/embeds_12.npy\n",
      "Saved to ../shards/npys/embeds_13.npy\n",
      "Saved to ../shards/npys/embeds_14.npy\n",
      "Saved to ../shards/npys/embeds_15.npy\n",
      "Saved to ../shards/npys/embeds_16.npy\n",
      "Saved to ../shards/npys/embeds_17.npy\n",
      "Saved to ../shards/npys/embeds_18.npy\n",
      "Saved to ../shards/npys/embeds_19.npy\n",
      "Saved to ../shards/npys/embeds_20.npy\n",
      "Saved to ../shards/npys/embeds_21.npy\n",
      "Saved to ../shards/npys/embeds_22.npy\n",
      "Saved to ../shards/npys/embeds_23.npy\n",
      "Saved to ../shards/npys/embeds_24.npy\n",
      "Saved to ../shards/npys/embeds_25.npy\n",
      "Saved to ../shards/npys/embeds_26.npy\n",
      "Saved to ../shards/npys/embeds_27.npy\n",
      "Saved to ../shards/npys/embeds_28.npy\n",
      "Saved to ../shards/npys/embeds_29.npy\n",
      "Saved to ../shards/npys/embeds_30.npy\n",
      "Saved to ../shards/npys/embeds_31.npy\n",
      "Saved to ../shards/npys/embeds_32.npy\n",
      "Saved to ../shards/npys/embeds_33.npy\n",
      "Saved to ../shards/npys/embeds_34.npy\n",
      "Saved to ../shards/npys/embeds_35.npy\n",
      "Saved to ../shards/npys/embeds_36.npy\n",
      "Saved to ../shards/npys/embeds_37.npy\n",
      "Saved to ../shards/npys/embeds_38.npy\n",
      "Saved to ../shards/npys/embeds_39.npy\n",
      "Saved to ../shards/npys/embeds_40.npy\n",
      "Saved to ../shards/npys/embeds_41.npy\n",
      "Saved to ../shards/npys/embeds_42.npy\n",
      "Saved to ../shards/npys/embeds_43.npy\n",
      "Saved to ../shards/npys/embeds_44.npy\n",
      "Saved to ../shards/npys/embeds_45.npy\n",
      "Saved to ../shards/npys/embeds_46.npy\n",
      "Saved to ../shards/npys/embeds_47.npy\n",
      "Saved to ../shards/npys/embeds_48.npy\n",
      "Saved to ../shards/npys/embeds_49.npy\n",
      "Saved to ../shards/npys/embeds_centroids.npy\n",
      "embeds_0.npy\n",
      "embeds_1.npy\n",
      "embeds_2.npy\n",
      "embeds_3.npy\n",
      "embeds_4.npy\n",
      "embeds_5.npy\n",
      "embeds_6.npy\n",
      "embeds_7.npy\n",
      "embeds_8.npy\n",
      "embeds_9.npy\n",
      "embeds_10.npy\n",
      "embeds_11.npy\n",
      "embeds_12.npy\n",
      "embeds_13.npy\n",
      "embeds_14.npy\n",
      "embeds_15.npy\n",
      "embeds_16.npy\n",
      "embeds_17.npy\n",
      "embeds_18.npy\n",
      "embeds_19.npy\n",
      "embeds_20.npy\n",
      "embeds_21.npy\n",
      "embeds_22.npy\n",
      "embeds_23.npy\n",
      "embeds_24.npy\n",
      "embeds_25.npy\n",
      "embeds_26.npy\n",
      "embeds_27.npy\n",
      "embeds_28.npy\n",
      "embeds_29.npy\n",
      "embeds_30.npy\n",
      "embeds_31.npy\n",
      "embeds_32.npy\n",
      "embeds_33.npy\n",
      "embeds_34.npy\n",
      "embeds_35.npy\n",
      "embeds_36.npy\n",
      "embeds_37.npy\n",
      "embeds_38.npy\n",
      "embeds_39.npy\n",
      "embeds_40.npy\n",
      "embeds_41.npy\n",
      "embeds_42.npy\n",
      "embeds_43.npy\n",
      "embeds_44.npy\n",
      "embeds_45.npy\n",
      "embeds_46.npy\n",
      "embeds_47.npy\n",
      "embeds_48.npy\n",
      "embeds_49.npy\n"
     ]
    }
   ],
   "source": [
    "# create multiple indexes\n",
    "dim = 64\n",
    "num_shards = 50\n",
    "npy_root = \"../shards/npys/\"\n",
    "index_root = \"../shards/idxs/\"\n",
    "\n",
    "# init empty npy arrays\n",
    "embeds_centroids = np.zeros((num_shards, dim))\n",
    "# create npy files\n",
    "for i in range(num_shards):\n",
    "    # embeds = random_embeddings(100000, dim)\n",
    "    random_mean = random_floats(1)\n",
    "    # random_std = random_floats(1)\n",
    "    random_std = [0.5]\n",
    "    embeds = random_normal_vectors(100000, dim, random_mean[0], random_std[0])\n",
    "    embeds_centroids[i] = compute_embeds_avgs(embeds)\n",
    "    save_np_to_file(os.path.join(npy_root, f\"embeds_{i}.npy\"), embeds)\n",
    "\n",
    "# save centroids\n",
    "save_np_to_file(os.path.join(npy_root, f\"embeds_centroids.npy\"), embeds_centroids)\n",
    "\n",
    "# create indexes\n",
    "for npy_path in os.listdir(npy_root):\n",
    "    if \"centroids\" in npy_path: \n",
    "        # create flat index\n",
    "        index = create_flat_index(os.path.join(npy_root, npy_path))\n",
    "        save_index(index, os.path.join(index_root, \"embeds_centroids.index\"))\n",
    "        continue\n",
    "    \n",
    "    print(npy_path)\n",
    "    index_prefix = npy_path.split(\".\")[0]\n",
    "    index = create_ivf_index(os.path.join(npy_root, npy_path))\n",
    "    save_index(index, os.path.join(index_root, f\"{index_prefix}.index\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load index\n",
    "def load_index(index_path):\n",
    "    return faiss.read_index(index_path)\n",
    "\n",
    "# query index\n",
    "def query_index(index, queries, k):\n",
    "    D, I = index.search(queries, k)\n",
    "    return D, I\n",
    "\n",
    "def query_index_file(index_path, queries, k):\n",
    "    index = load_index(index_path)\n",
    "    D, I = query_index(index, queries, k)\n",
    "    return D, I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing\n",
    "index = load_index(\"shards/idxs/embeds_1.index\")\n",
    "queries = random_queries(100, dim)\n",
    "# index.nprobe = 100\n",
    "D, I = query_index(index, queries, 1)\n",
    "\n",
    "index.is_trained\n",
    "# D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query shards/idxs/embeds_43.index   : 0.03076972s\n",
      "query shards/idxs/embeds_23.index   : 0.02722288s\n",
      "query shards/idxs/embeds_46.index   : 0.02610893s\n",
      "query shards/idxs/embeds_20.index   : 0.02791506s\n",
      "query shards/idxs/embeds_19.index   : 0.02585185s\n",
      "query shards/idxs/embeds_41.index   : 0.02887433s\n",
      "query shards/idxs/embeds_21.index   : 0.01999626s\n",
      "query shards/idxs/embeds_24.index   : 0.01883139s\n",
      "query shards/idxs/embeds_22.index   : 0.02385323s\n",
      "query shards/idxs/embeds_17.index   : 0.02589414s\n",
      "query shards/idxs/embeds_38.index   : 0.01358158s\n",
      "query shards/idxs/embeds_45.index   : 0.02614252s\n",
      "query shards/idxs/embeds_9.index    : 0.02599484s\n",
      "query shards/idxs/embeds_8.index    : 0.02581422s\n",
      "query shards/idxs/embeds_18.index   : 0.02590331s\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "User given query and k\n",
    "'''\n",
    "\n",
    "# num_file_visit * subk > k \n",
    "k = 5\n",
    "num_file_visit = 15\n",
    "subk = (k // num_file_visit) + k\n",
    "# print(subk)\n",
    "\n",
    "idx_paths = [os.path.join(index_root, f) for f in os.listdir(index_root)]\n",
    "# for now randomly select 3 index file to visit\n",
    "idxs = list(np.random.choice(idx_paths, num_file_visit, replace=False))\n",
    "\n",
    "D_concat = np.array([])\n",
    "I_concat = np.array([])\n",
    "file_idx_concat = np.array([])\n",
    "for i, idx_path in enumerate(idxs):\n",
    "    start_time = time.perf_counter()\n",
    "    D, I = query_index_file(idx_path, queries, subk)\n",
    "    end_time = time.perf_counter()\n",
    "    query_idx_time = end_time - start_time\n",
    "    # print query time 5digits\n",
    "    print(f\"query {idx_path:30}: {query_idx_time:.8f}s\")\n",
    "    # print(D, I)\n",
    "    # make idx_matrix: [[i, i], [i,i]...], shape same as D and I\n",
    "    file_idx = np.ones_like(D) * i\n",
    "    # print(file_idx)\n",
    "    D_concat = np.concatenate((D_concat, D), axis=1) if D_concat.size else D\n",
    "    I_concat = np.concatenate((I_concat, I), axis=1) if I_concat.size else I\n",
    "    file_idx_concat = np.concatenate((file_idx_concat, file_idx), axis=1) if file_idx_concat.size else file_idx\n",
    "\n",
    "# sort by distance, and also sort file_idx and I\n",
    "sort_idx = np.argsort(D_concat, axis=1)\n",
    "D_sorted = np.take_along_axis(D_concat, sort_idx, axis=1)\n",
    "I_sorted = np.take_along_axis(I_concat, sort_idx, axis=1)\n",
    "file_idx_sorted = np.take_along_axis(file_idx_concat, sort_idx, axis=1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_search(idx_file_list, queries, subk, verbose=False):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare distance across different indexes, get top k for the D_sorted and I_sorted, file_idx_sorted\n",
    "\n",
    "# get top k\n",
    "top_k = k\n",
    "top_k_idx = I_sorted[:, :top_k]\n",
    "top_k_dist = D_sorted[:, :top_k]\n",
    "top_k_file_idx = file_idx_sorted[:, :top_k]\n",
    "\n",
    "# print(top_k_file_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data class\n",
    "class IndexFileProfile:\n",
    "    '''\n",
    "    A data class to store a index file profile\n",
    "    '''\n",
    "    def __init__(self, idx_path, location, runtime, action):\n",
    "        self.idx_path = idx_path\n",
    "        # \"DRAM\" or \"CXL\"\n",
    "        self.location = location\n",
    "        self.runtime = runtime\n",
    "        # \"search\" or \"promotion\" or \"demotion\"\n",
    "        self.action = action\n",
    "\n",
    "    def return_dict(self):\n",
    "        return {\n",
    "            \"idx_path\": self.idx_path,\n",
    "            \"location\": self.location,\n",
    "            \"runtime\": self.runtime, \n",
    "            \"action\": self.action\n",
    "        }\n",
    "    \n",
    "class CXLLatencyFactorCalculator:\n",
    "    '''\n",
    "    Since we will only obtain DRAM time, we want to simulate the CXL time based on some factor (should be slower than DRAM)\n",
    "    Some determine factor: \n",
    "        - file size\n",
    "        - CXL memory size\n",
    "        - CXL bandwidth\n",
    "        - CXL mem usage (when it is high, CXL controller will be slower)\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def calculate_factor(self):\n",
    "        '''\n",
    "        Calculate the CXL latency factor\n",
    "        '''\n",
    "        # for now, just return a fixed value, 2 times slower than DRAM\n",
    "        return 2\n",
    "\n",
    "class IndexFileManager:\n",
    "    '''\n",
    "    Manage index files: actively move index files between DRAM and CXL based on some metric like query time (could potentially get infor from read logs)\n",
    "    '''\n",
    "    # CXL_Latency = 100\n",
    "    def __init__(self, idx_paths):\n",
    "        pass\n",
    "\n",
    "    def init_idx_location(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1. Query batch comes in\n",
    "2. Search top centriods \n",
    "3. Based on top centriods, find top index files to visit\n",
    "\n",
    "*. Index files placement optimization\n",
    "    Case 1: all index files are in DRAM. \n",
    "        - No NEED to move\n",
    "    Case 2: all index files are in CXL\n",
    "    Case 3: some index files are in DRAM, some are in CXL\n",
    "\n",
    "4. Query top index files\n",
    "5. Merge results and return\n",
    "\n",
    "Case 2 and 3: Need to move index files between DRAM and CXL\n",
    "    - Need to determine which index files to move\n",
    "        - Needs to be visited frequently\n",
    "    - Need to determine when to move\n",
    "        - Can overlap with search\n",
    "\n",
    "\n",
    "Traces\n",
    "    - Time steps\n",
    "    - Search profile\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-9, 9)\n",
      "(-8, 8)\n",
      "(-7, 7)\n",
      "(-6, 6)\n",
      "(-5, 5)\n",
      "(-4, 4)\n",
      "(-3, 3)\n",
      "(-2, 2)\n",
      "(-1, 1)\n",
      "(0, 0)\n"
     ]
    }
   ],
   "source": [
    "# create a Priority Queue with reverse order\n",
    "from queue import PriorityQueue\n",
    "\n",
    "pq = PriorityQueue()\n",
    "for i in range(10):\n",
    "    pq.put((-i, i))\n",
    "\n",
    "while not pq.empty():\n",
    "    print(pq.get())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<queue.PriorityQueue at 0x7f58c1685880>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Create a Priority Queue (-visit_count, idx)\n",
    "# Book keeping for each (idx, location)\n",
    "# Get one from the queue   \n",
    "    - if location is DRAM, query\n",
    "    - if location is CXL\n",
    "\n",
    "search priority queue\n",
    "    - (location, -visit_count, idx)\n",
    "\n",
    "move priority queue (CXL to DRAM or DRAM to CXL)\n",
    "    - (-visit_count, loc, idx)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
